{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split video into individual frames.\n",
    "def split_vid(path, output_path):\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        cv2.imwrite('{}/frame_{:05}.jpg'.format(output_path, count), image)\n",
    "        success, image = vidcap.read()\n",
    "        print('Read a new frame: {}'.format(success))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"data/train.mp4\")\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "for _ in range(50):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('frame2',rgb)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('opticalfb.png',frame2)\n",
    "        cv2.imwrite('opticalhsv.png',rgb)\n",
    "    prvs = next\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds = pd.read_csv('data/train.txt', names=['speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_arr = speeds['speed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV of a data frame where every row contains one frame and the previous frame, with the speed at the current frame\n",
    "\n",
    "rows = []\n",
    "\n",
    "\n",
    "for i in range(1, 2400):\n",
    "    prev = 'data/train_images/frame_{:05}.jpg'.format(i-1)\n",
    "    curr = 'data/train_images/frame_{:05}.jpg'.format(i)\n",
    "    rows.append([prev, curr, speeds_arr[i]])\n",
    "    \n",
    "df = pd.DataFrame(rows, columns=['prev', 'curr', 'speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/paired.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_df = pd.read_csv('data/paired.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(paired_df.drop('speed', axis=1), paired_df['speed'], test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"data/train.mp4\")\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('f', frame1)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_dim = (224, 224)\n",
    "resized = cv2.resize(frame1, square_dim, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('f', resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VGGNET model\n",
    "def vgg_model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv1'))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv2'))\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv3'))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv4'))\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv5'))\n",
    "    model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv6'))\n",
    "    model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv7'))\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv8'))\n",
    "    model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv9'))\n",
    "    model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv10'))\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv11'))\n",
    "    model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv12'))\n",
    "    model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='valid',\n",
    "                                 activation='relu', name='conv13'))\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    model.add(keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1000, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Farneback Flow Images \n",
    "# returns array of rbg values of farneback flow \n",
    "def fb_flow_from_df(data):\n",
    "    rgbs = []\n",
    "\n",
    "    for row in data.itertuples():\n",
    "        prev = cv2.imread(row[1], 0)\n",
    "        curr = cv2.imread(row[2], 0)\n",
    "        print('Files read')\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev, curr, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        hsv[...,0] = ang*180/np.pi/2\n",
    "        hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        rgbs.append(rgb)\n",
    "    \n",
    "    return np.array(rgbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = fb_flow_from_df(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = np.array(new_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(new_X_train, y_train, epochs=100, validation_split=.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training():\n",
    "    \n",
    "    cap = cv2.VideoCapture('data/train.mp4')\n",
    "    \n",
    "    speeds = pd.read_csv('data/train.txt', names=['speed'])\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    prev = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = np.zeros_like(frame)\n",
    "    hsv[...,1] = 255\n",
    "    \n",
    "    rgbs = []\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        curr = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(prev, curr, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        hsv[...,0] = ang*180/np.pi/2\n",
    "        hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        rgbs.append(cv2.resize(rgb, (224,224), interpolation=cv2.INTER_AREA))\n",
    "        \n",
    "        if len(rgbs)%100==0:\n",
    "            print('{} frames done'.format(len(rgbs)))\n",
    "    \n",
    "    return np.array(rgbs), speeds.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 frames done\n",
      "200 frames done\n",
      "300 frames done\n",
      "400 frames done\n",
      "500 frames done\n",
      "600 frames done\n",
      "700 frames done\n",
      "800 frames done\n",
      "900 frames done\n",
      "1000 frames done\n",
      "1100 frames done\n",
      "1200 frames done\n",
      "1300 frames done\n",
      "1400 frames done\n",
      "1500 frames done\n",
      "1600 frames done\n",
      "1700 frames done\n",
      "1800 frames done\n",
      "1900 frames done\n",
      "2000 frames done\n",
      "2100 frames done\n",
      "2200 frames done\n",
      "2300 frames done\n",
      "2400 frames done\n",
      "2500 frames done\n",
      "2600 frames done\n",
      "2700 frames done\n",
      "2800 frames done\n",
      "2900 frames done\n",
      "3000 frames done\n",
      "3100 frames done\n",
      "3200 frames done\n",
      "3300 frames done\n",
      "3400 frames done\n",
      "3500 frames done\n",
      "3600 frames done\n",
      "3700 frames done\n",
      "3800 frames done\n",
      "3900 frames done\n",
      "4000 frames done\n",
      "4100 frames done\n",
      "4200 frames done\n",
      "4300 frames done\n",
      "4400 frames done\n",
      "4500 frames done\n",
      "4600 frames done\n",
      "4700 frames done\n",
      "4800 frames done\n",
      "4900 frames done\n",
      "5000 frames done\n",
      "5100 frames done\n",
      "5200 frames done\n",
      "5300 frames done\n",
      "5400 frames done\n",
      "5500 frames done\n",
      "5600 frames done\n",
      "5700 frames done\n",
      "5800 frames done\n",
      "5900 frames done\n",
      "6000 frames done\n",
      "6100 frames done\n",
      "6200 frames done\n",
      "6300 frames done\n",
      "6400 frames done\n",
      "6500 frames done\n",
      "6600 frames done\n",
      "6700 frames done\n",
      "6800 frames done\n",
      "6900 frames done\n",
      "7000 frames done\n",
      "7100 frames done\n",
      "7200 frames done\n",
      "7300 frames done\n",
      "7400 frames done\n",
      "7500 frames done\n",
      "7600 frames done\n",
      "7700 frames done\n",
      "7800 frames done\n",
      "7900 frames done\n",
      "8000 frames done\n",
      "8100 frames done\n",
      "8200 frames done\n",
      "8300 frames done\n",
      "8400 frames done\n",
      "8500 frames done\n",
      "8600 frames done\n",
      "8700 frames done\n",
      "8800 frames done\n",
      "8900 frames done\n",
      "9000 frames done\n",
      "9100 frames done\n",
      "9200 frames done\n",
      "9300 frames done\n",
      "9400 frames done\n",
      "9500 frames done\n",
      "9600 frames done\n",
      "9700 frames done\n",
      "9800 frames done\n",
      "9900 frames done\n",
      "10000 frames done\n",
      "10100 frames done\n",
      "10200 frames done\n",
      "10300 frames done\n",
      "10400 frames done\n",
      "10500 frames done\n",
      "10600 frames done\n",
      "10700 frames done\n",
      "10800 frames done\n",
      "10900 frames done\n",
      "11000 frames done\n",
      "11100 frames done\n",
      "11200 frames done\n",
      "11300 frames done\n",
      "11400 frames done\n",
      "11500 frames done\n",
      "11600 frames done\n",
      "11700 frames done\n",
      "11800 frames done\n",
      "11900 frames done\n",
      "12000 frames done\n",
      "12100 frames done\n",
      "12200 frames done\n",
      "12300 frames done\n",
      "12400 frames done\n",
      "12500 frames done\n",
      "12600 frames done\n",
      "12700 frames done\n",
      "12800 frames done\n",
      "12900 frames done\n",
      "13000 frames done\n",
      "13100 frames done\n",
      "13200 frames done\n",
      "13300 frames done\n",
      "13400 frames done\n",
      "13500 frames done\n",
      "13600 frames done\n",
      "13700 frames done\n",
      "13800 frames done\n",
      "13900 frames done\n",
      "14000 frames done\n",
      "14100 frames done\n",
      "14200 frames done\n",
      "14300 frames done\n",
      "14400 frames done\n",
      "14500 frames done\n",
      "14600 frames done\n",
      "14700 frames done\n",
      "14800 frames done\n",
      "14900 frames done\n",
      "15000 frames done\n",
      "15100 frames done\n",
      "15200 frames done\n",
      "15300 frames done\n",
      "15400 frames done\n",
      "15500 frames done\n",
      "15600 frames done\n",
      "15700 frames done\n",
      "15800 frames done\n",
      "15900 frames done\n",
      "16000 frames done\n",
      "16100 frames done\n",
      "16200 frames done\n",
      "16300 frames done\n",
      "16400 frames done\n",
      "16500 frames done\n",
      "16600 frames done\n",
      "16700 frames done\n",
      "16800 frames done\n",
      "16900 frames done\n",
      "17000 frames done\n",
      "17100 frames done\n",
      "17200 frames done\n",
      "17300 frames done\n",
      "17400 frames done\n",
      "17500 frames done\n",
      "17600 frames done\n",
      "17700 frames done\n",
      "17800 frames done\n",
      "17900 frames done\n",
      "18000 frames done\n",
      "18100 frames done\n",
      "18200 frames done\n",
      "18300 frames done\n",
      "18400 frames done\n",
      "18500 frames done\n",
      "18600 frames done\n",
      "18700 frames done\n",
      "18800 frames done\n",
      "18900 frames done\n",
      "19000 frames done\n",
      "19100 frames done\n",
      "19200 frames done\n",
      "19300 frames done\n",
      "19400 frames done\n",
      "19500 frames done\n",
      "19600 frames done\n",
      "19700 frames done\n",
      "19800 frames done\n",
      "19900 frames done\n",
      "20000 frames done\n",
      "20100 frames done\n",
      "20200 frames done\n",
      "20300 frames done\n"
     ]
    }
   ],
   "source": [
    "images, speeds = build_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('processed_vid.npy', images, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_2 = np.load('processed_vid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
